# Implementation Plan: REQ-001 ì •ê·œì‹ ê¸°ë°˜ í¬ë¡¤ë§ ì—”ì§„

**Status**: ğŸ”„ In Progress
**Started**: 2025-02-12
**Last Updated**: 2026-02-13
**Estimated Completion**: -
**Phase 2 Completed**: 2026-02-12
**Phase 3 Completed**: 2026-02-12
**Phase 4 Completed**: 2026-02-12
**Phase 5 Completed**: 2026-02-12
**Phase 6 Completed**: 2026-02-13

---

**âš ï¸ CRITICAL INSTRUCTIONS**: After completing each phase:
1. âœ… Check off completed task checkboxes
2. ğŸ§ª Run all quality gate validation commands
3. âš ï¸ Verify ALL quality gate items pass
4. ğŸ“… Update "Last Updated" date above
5. ğŸ“ Document learnings in Notes section
6. â¡ï¸ Only then proceed to next phase

â›” **DO NOT skip quality gates or proceed with failing checks**

---

## ğŸ“‹ Overview

### Feature Description
LLM API ì—†ì´ ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì›¹ í˜ì´ì§€ êµ¬ì¡°ë¥¼ íŒŒì‹±í•˜ëŠ” ê²½ëŸ‰ í¬ë¡¤ë§ ì—”ì§„ êµ¬í˜„. EAZY í”„ë¡œì íŠ¸ì˜ ì²« ë²ˆì§¸ êµ¬í˜„ ë‹¨ê³„(REQ-001)ë¡œ, HTMLì—ì„œ ë§í¬, í¼, ë²„íŠ¼, ìŠ¤í¬ë¦½íŠ¸ ë‚´ API í˜¸ì¶œ íŒ¨í„´ì„ ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ê³ , í¬ë¡¤ë§ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ì‚¬ì´íŠ¸ë§µ ë° JSONìœ¼ë¡œ ì¶œë ¥í•œë‹¤. ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œë„ ë™ì‘í•˜ë©° ì™¸ë¶€ LLM ì˜ì¡´ì„±ì´ ì—†ë‹¤.

**ë¸Œëœì¹˜**: `feature/req-001-regex-crawler`
**ê¸°ìˆ  ìŠ¤íƒ**: Python 3.12+, httpx, pydantic, pytest, pytest-asyncio, pytest-cov, respx, ruff
**ì´ 16 TDD ì‚¬ì´í´, 80+ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤, ëª©í‘œ ì»¤ë²„ë¦¬ì§€ 80%+**

### Success Criteria
- [ ] ì •ê·œì‹ìœ¼ë¡œ HTMLì—ì„œ ë§í¬, í¼, ë²„íŠ¼, ìŠ¤í¬ë¦½íŠ¸ ë‚´ API í˜¸ì¶œ íŒ¨í„´ ì¶”ì¶œ
- [ ] í¬ë¡¤ë§ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ì‚¬ì´íŠ¸ë§µìœ¼ë¡œ ì €ì¥
- [ ] í¬ë¡¤ë§ ê¹Šì´ ë° ë²”ìœ„ë¥¼ ì‚¬ìš©ìê°€ ì„¤ì • ê°€ëŠ¥
- [ ] robots.txt ì¤€ìˆ˜ ì˜µì…˜ ì œê³µ
- [ ] LLM API ì—†ì´ ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œë„ ë™ì‘
- [ ] URL, íŒŒë¼ë¯¸í„°, ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡ì„ JSON í˜•íƒœë¡œ ì¶œë ¥

### User Impact
ë³´ì•ˆ í…ŒìŠ¤í„°ê°€ LLM API í‚¤ ì—†ì´ë„ ëŒ€ìƒ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ êµ¬ì¡°ë¥¼ ë¹ ë¥´ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤. ì •ê·œì‹ ê¸°ë°˜ì´ë¯€ë¡œ ì˜¤í”„ë¼ì¸/ì—ì–´ê°­ í™˜ê²½ì—ì„œë„ ë™ì‘í•˜ë©°, í›„ì† Phase(REQ-002 Smart Crawling, REQ-004 Vulnerability Scanning)ì˜ ê¸°ë°˜ ë°ì´í„°ë¥¼ ì œê³µí•œë‹¤.

---

## ğŸ—ï¸ Architecture Decisions

| Decision | Rationale | Trade-offs |
|----------|-----------|------------|
| ì •ê·œì‹ ê¸°ë°˜ íŒŒì‹± (BeautifulSoup/lxml ë¯¸ì‚¬ìš©) | LLM ì—†ëŠ” ê²½ëŸ‰ ì˜¤í”„ë¼ì¸ ë™ì‘, ì™¸ë¶€ ì˜ì¡´ì„± ìµœì†Œí™” | ë³µì¡í•œ HTML êµ¬ì¡° íŒŒì‹± ì •í™•ë„ ë‹¤ì†Œ ë‚®ìŒ |
| httpx AsyncClient ì‚¬ìš© | ë¹„ë™ê¸° ìš”ì²­ìœ¼ë¡œ í¬ë¡¤ë§ ì„±ëŠ¥ í™•ë³´, HTTP/2 ì§€ì› | requests ëŒ€ë¹„ í•™ìŠµ ê³¡ì„  |
| Pydantic v2 ë°ì´í„° ëª¨ë¸ | íƒ€ì… ì•ˆì „ì„±, JSON ì§ë ¬í™”, ìœ íš¨ì„± ê²€ì¦ ë‚´ì¥ | ëŸ°íƒ€ì„ ì˜¤ë²„í—¤ë“œ ë¯¸ë¯¸ |
| respxë¡œ HTTP ëª¨í‚¹ | httpx ë„¤ì´í‹°ë¸Œ ëª¨í‚¹, ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì—†ì´ í…ŒìŠ¤íŠ¸ | respx ì „ìš© (requests í˜¸í™˜ ì•ˆë¨) |
| uv íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € | ë¹ ë¥¸ ì˜ì¡´ì„± í•´ê²°, pyproject.toml ë„¤ì´í‹°ë¸Œ | pip ëŒ€ë¹„ ìƒíƒœê³„ ì‘ìŒ |

---

## ğŸ“¦ Dependencies

### Required Before Starting
- [x] PRD ë¬¸ì„œ ê²€í†  ì™„ë£Œ (`plan/PRD.md`)
- [x] Python 3.12+ ì„¤ì¹˜ í™•ì¸
- [x] uv íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì„¤ì¹˜ í™•ì¸

### External Dependencies
- httpx: ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸
- pydantic: ë°ì´í„° ëª¨ë¸ ë° ìœ íš¨ì„± ê²€ì¦
- pytest: í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
- pytest-asyncio: ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì§€ì›
- pytest-cov: í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
- respx: httpx ì „ìš© HTTP ëª¨í‚¹
- ruff: ë¦°íŒ… ë° í¬ë§·íŒ…

---

## ğŸ§ª Test Strategy

### Testing Approach
**TDD Principle**: í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±(RED)í•˜ê³ , ìµœì†Œ êµ¬í˜„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼(GREEN)ì‹œí‚¨ ë’¤, ë¦¬íŒ©í† ë§(BLUE)í•œë‹¤.

### Test Pyramid for This Feature
| Test Type | Coverage Target | Purpose |
|-----------|-----------------|---------|
| **Unit Tests** | â‰¥80% | ì •ê·œì‹ íŒŒì‹±, URL ì²˜ë¦¬, robots.txt íŒŒì‹±, HTTP í´ë¼ì´ì–¸íŠ¸, ì‚¬ì´íŠ¸ë§µ, ë‚´ë³´ë‚´ê¸° |
| **Integration Tests** | í•µì‹¬ ê²½ë¡œ | í¬ë¡¤ë§ ì—”ì§„ ì „ì²´ ì›Œí¬í”Œë¡œìš° (URL ì…ë ¥ â†’ í¬ë¡¤ë§ â†’ JSON ì¶œë ¥) |

### Test File Organization
```
tests/
â”œâ”€â”€ conftest.py
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ test_crawl_types.py
â”‚   â””â”€â”€ crawler/
â”‚       â”œâ”€â”€ test_regex_parser.py
â”‚       â”œâ”€â”€ test_url_resolver.py
â”‚       â”œâ”€â”€ test_robots_parser.py
â”‚       â”œâ”€â”€ test_http_client.py
â”‚       â”œâ”€â”€ test_sitemap.py
â”‚       â””â”€â”€ test_exporter.py
â””â”€â”€ integration/
    â””â”€â”€ crawler/
        â””â”€â”€ test_crawler_engine.py
```

### Coverage Requirements by Phase
- **Phase 1 (í”„ë¡œì íŠ¸ ì´ˆê¸°í™” + ë°ì´í„° ëª¨ë¸)**: Pydantic ëª¨ë¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (â‰¥80%)
- **Phase 2 (HTML Regex Parser)**: ì •ê·œì‹ íŒŒì‹± í•¨ìˆ˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (â‰¥80%)
- **Phase 3 (URL Resolver)**: URL ë³€í™˜/ì •ê·œí™”/í•„í„°ë§ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (â‰¥80%)
- **Phase 4 (Robots.txt Parser)**: robots.txt íŒŒì‹± ë° í—ˆìš© íŒë‹¨ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (â‰¥80%)
- **Phase 5 (HTTP Client)**: ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (â‰¥80%)
- **Phase 6 (Sitemap & Exporter)**: ì‚¬ì´íŠ¸ë§µ/ë‚´ë³´ë‚´ê¸° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (â‰¥80%)
- **Phase 7 (Crawler Engine í†µí•©)**: í†µí•© í…ŒìŠ¤íŠ¸ + ì „ì²´ ì»¤ë²„ë¦¬ì§€ 80%+

### Test Naming Convention
```python
# pytest ê¸°ë°˜ í…ŒìŠ¤íŠ¸ êµ¬ì¡°:
# íŒŒì¼ëª…: test_{module_name}.py
# í´ë˜ìŠ¤: Test{ComponentName}
# í•¨ìˆ˜: test_{í–‰ìœ„}_{ì¡°ê±´}_{ê¸°ëŒ€ê²°ê³¼}
# ì˜ˆ: test_extract_links_from_empty_html_returns_empty_list
# Arrange â†’ Act â†’ Assert íŒ¨í„´ ì‚¬ìš©
```

---

## ğŸš€ Implementation Phases

### Phase 1: í”„ë¡œì íŠ¸ ì´ˆê¸°í™” + ë°ì´í„° ëª¨ë¸
**Goal**: í”„ë¡œì íŠ¸ ê¸°ë°˜ êµ¬ì¡° êµ¬ì¶• ë° í•µì‹¬ ë°ì´í„° ëª¨ë¸ ì •ì˜
**Status**: âœ… Complete

#### Tasks

**ì‚¬ì „ ì‘ì—… (non-TDD):**
- [x] **Task 0.0**: í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
  - `feature/req-001-regex-crawler` ë¸Œëœì¹˜ ìƒì„±
  - `uv init` â†’ pyproject.toml ìƒì„±
  - .gitignore, ë””ë ‰í† ë¦¬ êµ¬ì¡°, pytest/ruff ì„¤ì •
  - ì˜ì¡´ì„± ì„¤ì¹˜ (httpx, pydantic, pytest, pytest-asyncio, pytest-cov, respx, ruff)

**ğŸ”´ RED: Write Failing Tests First (TDD-0.1: ë°ì´í„° ëª¨ë¸)**
- [x] **Test 0.1**: í¬ë¡¤ë§ ë°ì´í„° ëª¨ë¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/models/test_crawl_types.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (ëª¨ë¸ ë¯¸êµ¬í˜„ ìƒíƒœ) â†’ âœ… ModuleNotFoundError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - CrawlConfig ê¸°ë³¸ê°’ ê²€ì¦ (max_depth=3, respect_robots=True ë“±)
    - PageResult ìƒì„± ë° í•„ë“œ ê²€ì¦
    - FormData í•„ë“œ ê²€ì¦ (action, method, inputs)
    - EndpointInfo í•„ë“œ ê²€ì¦ (url, method, source)
    - ButtonInfo í•„ë“œ ê²€ì¦
    - CrawlResult JSON ì§ë ¬í™”/ì—­ì§ë ¬í™”

**ğŸŸ¢ GREEN: Implement to Make Tests Pass**
- [x] **Task 0.2**: Pydantic ë°ì´í„° ëª¨ë¸ êµ¬í˜„
  - File(s): `src/eazy/models/crawl_types.py`
  - Goal: Test 0.1 ì „ì²´ í†µê³¼ â†’ âœ… 17/17 passed
  - Details: Pydantic BaseModel ìƒì† ëª¨ë¸ êµ¬í˜„ (CrawlConfig, PageResult, FormData, EndpointInfo, ButtonInfo, CrawlResult)

**ğŸ”µ REFACTOR: Clean Up Code**
- [x] **Task 0.3**: ë°ì´í„° ëª¨ë¸ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/models/crawl_types.py`
  - Goal: í…ŒìŠ¤íŠ¸ í†µê³¼ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ í’ˆì§ˆ ê°œì„  â†’ âœ… 17/17 passed
  - Checklist:
    - [x] model_config ì„¤ì • ìµœì í™” (CrawlConfig frozen=True)
    - [x] í•„ë“œ ê¸°ë³¸ê°’ ë° validators ì •ë¦¬ (Field(default_factory=...) ì ìš©)
    - [x] ì¸ë¼ì¸ ë¬¸ì„œí™” ì¶”ê°€ (Google ìŠ¤íƒ€ì¼ Attributes docstring)
    - [x] ë¶ˆí•„ìš”í•œ ì½”ë“œ ì œê±°

#### Commits
```
chore: initialize project with uv, pytest, ruff
test(models): add failing tests for crawl data models
feat(models): implement crawl data models with pydantic
refactor(models): optimize data model configuration
```

#### Quality Gate âœ‹

**âš ï¸ STOP: Phase 2 ì§„í–‰ ì „ ëª¨ë“  ì²´í¬ í•­ëª©ì„ í†µê³¼í•´ì•¼ í•¨**

**TDD Compliance** (CRITICAL):
- [x] **Red Phase**: í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ê³  ì‹¤íŒ¨ í™•ì¸ (ModuleNotFoundError)
- [x] **Green Phase**: ìµœì†Œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼ (17/17 passed)
- [x] **Refactor Phase**: í…ŒìŠ¤íŠ¸ í†µê³¼ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ ê°œì„  (frozen, Field, docstrings)
- [x] **Coverage Check**: ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (100%, ëª©í‘œ 80%+)
  ```bash
  # ì»¤ë²„ë¦¬ì§€ í™•ì¸
  uv run pytest --cov=src/eazy --cov-report=term-missing
  ```

**Build & Tests**:
- [x] **Build**: í”„ë¡œì íŠ¸ ë¹Œë“œ/ì»´íŒŒì¼ ì—ëŸ¬ ì—†ìŒ
- [x] **All Tests Pass**: 100% í…ŒìŠ¤íŠ¸ í†µê³¼ (17/17, ìŠ¤í‚µ ì—†ìŒ)
- [x] **Test Performance**: í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ 0.05ì´ˆ ì™„ë£Œ
- [x] **No Flaky Tests**: í…ŒìŠ¤íŠ¸ ì¼ê´€ í†µê³¼ í™•ì¸

**Code Quality**:
- [x] **Linting**: ë¦°íŒ… ì—ëŸ¬/ê²½ê³  ì—†ìŒ (ruff check passed)
- [x] **Formatting**: í”„ë¡œì íŠ¸ í‘œì¤€ì— ë§ëŠ” í¬ë§·íŒ… (ruff format passed)
- [x] **Type Safety**: ëª¨ë“  í•„ë“œ íƒ€ì… íŒíŠ¸ ì ìš©
- [x] **Static Analysis**: ì •ì  ë¶„ì„ ë„êµ¬ ì‹¬ê° ì´ìŠˆ ì—†ìŒ

**Security & Performance**:
- [x] **Dependencies**: ì•Œë ¤ì§„ ë³´ì•ˆ ì·¨ì•½ì  ì—†ìŒ
- [x] **Performance**: ì„±ëŠ¥ ì €í•˜ ì—†ìŒ
- [x] **Memory**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜/ìì› ì´ìŠˆ ì—†ìŒ
- [x] **Error Handling**: Pydantic ValidationErrorë¡œ ì˜ëª»ëœ ì…ë ¥ ì²˜ë¦¬

**Documentation**:
- [x] **Code Comments**: Google ìŠ¤íƒ€ì¼ Attributes docstring ì¶”ê°€
- [x] **API Docs**: ê³µê°œ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì„œí™” (ëª¨ë“  ëª¨ë¸ docstring)
- [x] **README**: N/A (Phase 1)

**Manual Testing**:
- [x] **Functionality**: ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸
- [x] **Edge Cases**: ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [x] **Error States**: ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ

**Validation Commands**:
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
uv run pytest --cov=src/eazy --cov-report=term-missing

# ë¦°íŒ…
uv run ruff check src/ tests/

# í¬ë§·íŒ…
uv run ruff format --check src/ tests/

# ì „ì²´ ê²€ì¦ (í•œ ì¤„)
uv run pytest --cov=src/eazy --cov-report=term-missing && uv run ruff check src/ tests/ && uv run ruff format --check src/ tests/
```

**Manual Test Checklist**:
- [x] CrawlConfig() ê¸°ë³¸ê°’ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
- [x] CrawlResult.model_dump_json() ì¶œë ¥ ìŠ¤í‚¤ë§ˆ í™•ì¸
- [x] ì˜ëª»ëœ íƒ€ì… ì…ë ¥ ì‹œ ValidationError ë°œìƒ í™•ì¸

---

### Phase 2: HTML Regex Parser
**Goal**: HTMLì—ì„œ ë§í¬, í¼, ë²„íŠ¼, API í˜¸ì¶œ íŒ¨í„´ì„ ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œ
**Status**: âœ… Complete

#### Tasks

**ğŸ”´ RED: Write Failing Tests First (TDD-1.1: ë§í¬ ì¶”ì¶œ)**
- [x] **Test 1.1**: ë§í¬ ì¶”ì¶œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_regex_parser.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ImportError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ê¸°ë³¸ `<a href="...">` ë§í¬ ì¶”ì¶œ
    - ë‹¤ì¤‘ ë§í¬ ì¶”ì¶œ
    - ë¹ˆ HTMLì—ì„œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    - href ì—†ëŠ” `<a>` íƒœê·¸ ë¬´ì‹œ
    - ì‘ì€ë”°ì˜´í‘œ/í°ë”°ì˜´í‘œ ëª¨ë‘ ì²˜ë¦¬
    - javascript:, mailto:, tel: í”„ë¡œí† ì½œ ë¬´ì‹œ

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-1.1)**
- [x] **Task 1.1**: ë§í¬ ì¶”ì¶œ í•¨ìˆ˜ êµ¬í˜„
  - File(s): `src/eazy/crawler/regex_parser.py`
  - Goal: Test 1.1 í†µê³¼ â†’ âœ… 6/6 passed
  - Details: `extract_links(html: str) -> list[str]` êµ¬í˜„

**ğŸ”µ REFACTOR (TDD-1.1)**
- [x] **Task 1.1R**: ë§í¬ ì¶”ì¶œ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/regex_parser.py`
  - Goal: ì •ê·œì‹ ì»´íŒŒì¼ ìµœì í™” (ëª¨ë“ˆ ë ˆë²¨ ìƒìˆ˜) â†’ âœ… 6/6 passed

**ğŸ”´ RED: Write Failing Tests First (TDD-1.2: í¼ ì¶”ì¶œ)**
- [x] **Test 1.2**: í¼ ì¶”ì¶œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_regex_parser.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… AttributeError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ê¸°ë³¸ `<form>` ì¶”ì¶œ (action, method)
    - `<input>` í•„ë“œ ì¶”ì¶œ (name, type, value)
    - ë‹¤ì¤‘ í¼ ì¶”ì¶œ
    - action ì—†ëŠ” í¼ ì²˜ë¦¬
    - ê¸°ë³¸ method=GET
    - `<select>`, `<textarea>` ì¶”ì¶œ
    - hidden input ì¶”ì¶œ

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-1.2)**
- [x] **Task 1.2**: í¼ ì¶”ì¶œ í•¨ìˆ˜ êµ¬í˜„
  - File(s): `src/eazy/crawler/regex_parser.py`
  - Goal: Test 1.2 í†µê³¼ â†’ âœ… 13/13 passed
  - Details: `extract_forms(html: str, base_url: str) -> list[FormData]` êµ¬í˜„

**ğŸ”µ REFACTOR (TDD-1.2)**
- [x] **Task 1.2R**: í¼ ì¶”ì¶œ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/regex_parser.py`
  - Goal: ì½”ë“œ í’ˆì§ˆ ê°œì„  â†’ âœ… 13/13 passed

**ğŸ”´ RED: Write Failing Tests First (TDD-1.3: ë²„íŠ¼ ì¶”ì¶œ)**
- [x] **Test 1.3**: ë²„íŠ¼ ì¶”ì¶œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_regex_parser.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… AttributeError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ê¸°ë³¸ `<button>` ì¶”ì¶œ
    - onclick ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì¶”ì¶œ
    - submit íƒ€ì… ë²„íŠ¼

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-1.3)**
- [x] **Task 1.3**: ë²„íŠ¼ ì¶”ì¶œ í•¨ìˆ˜ êµ¬í˜„
  - File(s): `src/eazy/crawler/regex_parser.py`
  - Goal: Test 1.3 í†µê³¼ â†’ âœ… 18/18 passed
  - Details: `extract_buttons(html: str) -> list[ButtonInfo]` êµ¬í˜„

**ğŸ”µ REFACTOR (TDD-1.3)**
- [x] **Task 1.3R**: ë²„íŠ¼ ì¶”ì¶œ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/regex_parser.py`
  - Goal: ì½”ë“œ í’ˆì§ˆ ê°œì„  â†’ âœ… 18/18 passed

**ğŸ”´ RED: Write Failing Tests First (TDD-1.4: API í˜¸ì¶œ íŒ¨í„´ ì¶”ì¶œ)**
- [x] **Test 1.4**: API í˜¸ì¶œ íŒ¨í„´ ì¶”ì¶œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_regex_parser.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ImportError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - `fetch('/api/...')` íŒ¨í„´
    - `axios.get/post(...)` íŒ¨í„´
    - `XMLHttpRequest` open íŒ¨í„´
    - jQuery `$.ajax(...)` íŒ¨í„´
    - ì „ì²´ URL (`https://api.example.com/...`)
    - ë¹ˆ HTML ì²˜ë¦¬
    - ì¤‘ë³µ ì œê±°

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-1.4)**
- [x] **Task 1.4**: API í˜¸ì¶œ íŒ¨í„´ ì¶”ì¶œ í•¨ìˆ˜ êµ¬í˜„
  - File(s): `src/eazy/crawler/regex_parser.py`
  - Goal: Test 1.4 í†µê³¼ â†’ âœ… 25/25 passed
  - Details: `extract_api_endpoints(html: str) -> list[EndpointInfo]` êµ¬í˜„

**ğŸ”µ REFACTOR (TDD-1.4)**
- [x] **Task 1.4R**: API í˜¸ì¶œ íŒ¨í„´ ì¶”ì¶œ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/regex_parser.py`
  - Goal: ì •ê·œì‹ íŒ¨í„´ ìµœì í™” â†’ âœ… 25/25 passed

#### Commits
```
test(crawler): add failing tests for link extraction
feat(crawler): implement link extraction with regex
refactor(crawler): optimize link extraction regex patterns
test(crawler): add failing tests for form extraction
feat(crawler): implement form extraction
refactor(crawler): improve form extraction code quality
test(crawler): add failing tests for button extraction
feat(crawler): implement button extraction
refactor(crawler): improve button extraction code quality
test(crawler): add failing tests for API endpoint extraction
feat(crawler): implement API endpoint extraction
refactor(crawler): optimize API endpoint extraction patterns
```

#### Quality Gate âœ‹

**âš ï¸ STOP: Phase 3 ì§„í–‰ ì „ ëª¨ë“  ì²´í¬ í•­ëª©ì„ í†µê³¼í•´ì•¼ í•¨**

**TDD Compliance** (CRITICAL):
- [x] **Red Phase**: í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ê³  ì‹¤íŒ¨ í™•ì¸ (ImportError/AttributeError)
- [x] **Green Phase**: ìµœì†Œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼ (25/25 passed)
- [x] **Refactor Phase**: í…ŒìŠ¤íŠ¸ í†µê³¼ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ ê°œì„ 
- [x] **Coverage Check**: ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (100%, ëª©í‘œ 80%+)
  ```bash
  # ì»¤ë²„ë¦¬ì§€ í™•ì¸
  uv run pytest tests/unit/crawler/ --cov=src/eazy/crawler --cov-report=term-missing
  # Result: 93/93 statements, 100% coverage
  ```

**Build & Tests**:
- [x] **Build**: í”„ë¡œì íŠ¸ ë¹Œë“œ/ì»´íŒŒì¼ ì—ëŸ¬ ì—†ìŒ
- [x] **All Tests Pass**: 100% í…ŒìŠ¤íŠ¸ í†µê³¼ (25/25, ìŠ¤í‚µ ì—†ìŒ)
- [x] **Test Performance**: í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ 0.05ì´ˆ ì™„ë£Œ
- [x] **No Flaky Tests**: í…ŒìŠ¤íŠ¸ ì¼ê´€ í†µê³¼ í™•ì¸

**Code Quality**:
- [x] **Linting**: ë¦°íŒ… ì—ëŸ¬/ê²½ê³  ì—†ìŒ (ruff check passed)
- [x] **Formatting**: í”„ë¡œì íŠ¸ í‘œì¤€ì— ë§ëŠ” í¬ë§·íŒ… (ruff format applied)
- [x] **Type Safety**: ëª¨ë“  í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ íƒ€ì… íŒíŠ¸ ì ìš©
- [x] **Static Analysis**: ì •ì  ë¶„ì„ ë„êµ¬ ì‹¬ê° ì´ìŠˆ ì—†ìŒ

**Security & Performance**:
- [x] **Dependencies**: ì•Œë ¤ì§„ ë³´ì•ˆ ì·¨ì•½ì  ì—†ìŒ
- [x] **Performance**: ì„±ëŠ¥ ì €í•˜ ì—†ìŒ (ëª¨ë“ˆ ë ˆë²¨ ì •ê·œì‹ ì»´íŒŒì¼)
- [x] **Memory**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜/ìì› ì´ìŠˆ ì—†ìŒ
- [x] **Error Handling**: ë¹ˆ HTML, ì˜ëª»ëœ í˜•ì‹ ë“± ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬

**Documentation**:
- [x] **Code Comments**: Google ìŠ¤íƒ€ì¼ docstring ì¶”ê°€
- [x] **API Docs**: ê³µê°œ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì„œí™” (ëª¨ë“  í•¨ìˆ˜ docstring)
- [x] **README**: N/A (Phase 2)

**Manual Testing**:
- [x] **Functionality**: ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸
- [x] **Edge Cases**: ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [x] **Error States**: ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ

**Validation Commands**:
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest tests/unit/crawler/

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
uv run pytest tests/unit/crawler/ --cov=src/eazy/crawler --cov-report=term-missing

# ë¦°íŒ…
uv run ruff check src/eazy/crawler/ tests/unit/crawler/

# í¬ë§·íŒ… í™•ì¸
uv run ruff format --check src/eazy/crawler/ tests/unit/crawler/

# ì „ì²´ ê²€ì¦ (í•œ ì¤„)
uv run pytest tests/unit/crawler/ --cov=src/eazy/crawler --cov-report=term-missing && uv run ruff check src/eazy/crawler/ tests/unit/crawler/
```

**Manual Test Checklist**:
- [x] ì‹¤ì œ HTML ìƒ˜í”Œì—ì„œ ë§í¬ ì¶”ì¶œ ê²°ê³¼ í™•ì¸
- [x] ë³µì¡í•œ í¼(ë‹¤ì¤‘ input, select, textarea)ì—ì„œ ì •í™•í•œ ì¶”ì¶œ í™•ì¸
- [x] JavaScript ì½”ë“œ ë‚´ API í˜¸ì¶œ íŒ¨í„´ ê°ì§€ í™•ì¸

---

### Phase 3: URL Resolver
**Goal**: ìƒëŒ€/ì ˆëŒ€ URL ë³€í™˜, ì •ê·œí™”, ìŠ¤ì½”í”„ í•„í„°ë§
**Status**: âœ… Complete

#### Tasks

**ğŸ”´ RED: Write Failing Tests First (TDD-2.1: URL ë³€í™˜)**
- [x] **Test 2.1**: URL ë³€í™˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_url_resolver.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ModuleNotFoundError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ìƒëŒ€ ê²½ë¡œ â†’ ì ˆëŒ€ URL ë³€í™˜
    - protocol-relative URL (//) ì²˜ë¦¬
    - ë¶€ëª¨ ê²½ë¡œ (../) í•´ì„
    - fragment-only (#section) â†’ None ë°˜í™˜
    - ë¹ˆ href â†’ None ë°˜í™˜
    - ì´ë¯¸ ì ˆëŒ€ URL â†’ ê·¸ëŒ€ë¡œ ë°˜í™˜

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-2.1)**
- [x] **Task 2.1**: URL ë³€í™˜ í•¨ìˆ˜ êµ¬í˜„
  - File(s): `src/eazy/crawler/url_resolver.py`
  - Goal: Test 2.1 í†µê³¼ â†’ âœ… 6/6 passed
  - Details: `resolve_url(base_url: str, href: str) -> str | None` êµ¬í˜„

**ğŸ”µ REFACTOR (TDD-2.1)**
- [x] **Task 2.1R**: URL ë³€í™˜ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/url_resolver.py`
  - Goal: ì½”ë“œ í’ˆì§ˆ ê°œì„  â†’ âœ… 6/6 passed (ì´ë¯¸ ìµœì  ìƒíƒœ)

**ğŸ”´ RED: Write Failing Tests First (TDD-2.2: URL ì •ê·œí™”)**
- [x] **Test 2.2**: URL ì •ê·œí™” ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_url_resolver.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ImportError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - fragment ì œê±° (url#section â†’ url)
    - trailing slash ì •ê·œí™”
    - scheme/host ì†Œë¬¸ì ë³€í™˜
    - ê¸°ë³¸ í¬íŠ¸ ì œê±° (:80, :443)
    - ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° í‚¤ ê¸°ì¤€ ì •ë ¬
    - ë¹„í‘œì¤€ í¬íŠ¸ ìœ ì§€ (:8080)

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-2.2)**
- [x] **Task 2.2**: URL ì •ê·œí™” í•¨ìˆ˜ êµ¬í˜„
  - File(s): `src/eazy/crawler/url_resolver.py`
  - Goal: Test 2.2 í†µê³¼ â†’ âœ… 13/13 passed
  - Details: `normalize_url(url: str) -> str` êµ¬í˜„

**ğŸ”µ REFACTOR (TDD-2.2)**
- [x] **Task 2.2R**: URL ì •ê·œí™” ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/url_resolver.py`
  - Goal: URL ì •ê·œí™” ë¡œì§ ìµœì í™” â†’ âœ… 13/13 passed (ì´ë¯¸ ìµœì  ìƒíƒœ)

**ğŸ”´ RED: Write Failing Tests First (TDD-2.3: ìŠ¤ì½”í”„ í•„í„°ë§)**
- [x] **Test 2.3**: ìŠ¤ì½”í”„ í•„í„°ë§ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_url_resolver.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ImportError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ê°™ì€ ë„ë©”ì¸ â†’ True
    - ë‹¤ë¥¸ ë„ë©”ì¸ â†’ False
    - ì„œë¸Œë„ë©”ì¸ í¬í•¨ ì˜µì…˜
    - ê²½ë¡œ ì ‘ë‘ì‚¬ í•„í„°
    - ì œì™¸ íŒ¨í„´ (*.pdf, /admin/*)

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-2.3)**
- [x] **Task 2.3**: ìŠ¤ì½”í”„ í•„í„°ë§ í•¨ìˆ˜ êµ¬í˜„
  - File(s): `src/eazy/crawler/url_resolver.py`
  - Goal: Test 2.3 í†µê³¼ â†’ âœ… 20/20 passed
  - Details: `is_in_scope(url: str, config: CrawlConfig) -> bool` êµ¬í˜„

**ğŸ”µ REFACTOR (TDD-2.3)**
- [x] **Task 2.3R**: ìŠ¤ì½”í”„ í•„í„°ë§ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/url_resolver.py`
  - Goal: ì½”ë“œ í’ˆì§ˆ ê°œì„  â†’ âœ… 20/20 passed (ì´ë¯¸ ìµœì  ìƒíƒœ)

#### Commits
```
test(crawler): add failing tests for URL resolution
feat(crawler): implement URL resolution
refactor(crawler): improve URL resolution code quality
test(crawler): add failing tests for URL normalization
feat(crawler): implement URL normalization
refactor(crawler): optimize URL normalization
test(crawler): add failing tests for scope filtering
feat(crawler): implement scope filtering
refactor(crawler): improve scope filtering code quality
```

#### Quality Gate âœ‹

**âš ï¸ STOP: Phase 4 ì§„í–‰ ì „ ëª¨ë“  ì²´í¬ í•­ëª©ì„ í†µê³¼í•´ì•¼ í•¨**

**TDD Compliance** (CRITICAL):
- [x] **Red Phase**: í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ê³  ì‹¤íŒ¨ í™•ì¸ (ModuleNotFoundError/ImportError)
- [x] **Green Phase**: ìµœì†Œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼ (20/20 passed)
- [x] **Refactor Phase**: í…ŒìŠ¤íŠ¸ í†µê³¼ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ ê°œì„ 
- [x] **Coverage Check**: ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (96%, ëª©í‘œ 80%+)
  ```bash
  # ì»¤ë²„ë¦¬ì§€ í™•ì¸
  uv run pytest tests/unit/crawler/test_url_resolver.py --cov=eazy.crawler.url_resolver --cov-report=term-missing
  # Result: 52 statements, 2 missed, 96% coverage
  ```

**Build & Tests**:
- [x] **Build**: í”„ë¡œì íŠ¸ ë¹Œë“œ/ì»´íŒŒì¼ ì—ëŸ¬ ì—†ìŒ
- [x] **All Tests Pass**: 100% í…ŒìŠ¤íŠ¸ í†µê³¼ (62/62 ì „ì²´, 20/20 url_resolver, ìŠ¤í‚µ ì—†ìŒ)
- [x] **Test Performance**: í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ 0.07ì´ˆ ì™„ë£Œ
- [x] **No Flaky Tests**: í…ŒìŠ¤íŠ¸ ì¼ê´€ í†µê³¼ í™•ì¸

**Code Quality**:
- [x] **Linting**: ë¦°íŒ… ì—ëŸ¬/ê²½ê³  ì—†ìŒ (ruff check passed)
- [x] **Formatting**: í”„ë¡œì íŠ¸ í‘œì¤€ì— ë§ëŠ” í¬ë§·íŒ… (ruff format passed)
- [x] **Type Safety**: ëª¨ë“  í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ íƒ€ì… íŒíŠ¸ ì ìš©
- [x] **Static Analysis**: ì •ì  ë¶„ì„ ë„êµ¬ ì‹¬ê° ì´ìŠˆ ì—†ìŒ

**Security & Performance**:
- [x] **Dependencies**: ì•Œë ¤ì§„ ë³´ì•ˆ ì·¨ì•½ì  ì—†ìŒ (stdlibë§Œ ì‚¬ìš©)
- [x] **Performance**: ì„±ëŠ¥ ì €í•˜ ì—†ìŒ
- [x] **Memory**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜/ìì› ì´ìŠˆ ì—†ìŒ
- [x] **Error Handling**: ë¹ˆ href, fragment-only ë“± ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬

**Documentation**:
- [x] **Code Comments**: Google ìŠ¤íƒ€ì¼ docstring ì¶”ê°€
- [x] **API Docs**: ê³µê°œ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì„œí™” (ëª¨ë“  í•¨ìˆ˜ docstring)
- [x] **README**: N/A (Phase 3)

**Manual Testing**:
- [x] **Functionality**: ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸
- [x] **Edge Cases**: ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [x] **Error States**: ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ

**Validation Commands**:
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest tests/unit/crawler/test_url_resolver.py -v

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
uv run pytest tests/unit/crawler/test_url_resolver.py --cov=eazy.crawler.url_resolver --cov-report=term-missing

# ë¦°íŒ…
uv run ruff check src/eazy/crawler/url_resolver.py tests/unit/crawler/test_url_resolver.py

# í¬ë§·íŒ… í™•ì¸
uv run ruff format --check src/eazy/crawler/url_resolver.py tests/unit/crawler/test_url_resolver.py

# ì „ì²´ íšŒê·€ í…ŒìŠ¤íŠ¸
uv run pytest --cov=src/eazy --cov-report=term-missing
```

**Manual Test Checklist**:
- [x] ë‹¤ì–‘í•œ ìƒëŒ€ URL ë³€í™˜ ê²°ê³¼ í™•ì¸
- [x] ì •ê·œí™” í›„ ë™ì¼ URL ì¤‘ë³µ ì œê±° í™•ì¸
- [x] ë„ë©”ì¸ ì™¸ë¶€ URL ì •í™•íˆ í•„í„°ë§ë˜ëŠ”ì§€ í™•ì¸

---

### Phase 4: Robots.txt Parser
**Goal**: robots.txt íŒŒì‹± ë° URL í—ˆìš©/ì°¨ë‹¨ íŒë‹¨
**Status**: âœ… Complete

#### Tasks

**ğŸ”´ RED: Write Failing Tests First (TDD-3.1: robots.txt íŒŒì‹±)**
- [x] **Test 3.1**: robots.txt íŒŒì‹± ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_robots_parser.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ModuleNotFoundError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ê¸°ë³¸ User-agent/Disallow íŒŒì‹±
    - ë¹ˆ robots.txt ì²˜ë¦¬
    - ì£¼ì„(#) ë¬´ì‹œ
    - ë‹¤ì¤‘ User-agent ë¸”ë¡
    - Allow/Disallow ìš°ì„ ìˆœìœ„
    - Crawl-delay íŒŒì‹±

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-3.1)**
- [x] **Task 3.1**: RobotsParser í´ë˜ìŠ¤ êµ¬í˜„
  - File(s): `src/eazy/crawler/robots_parser.py`
  - Goal: Test 3.1 í†µê³¼ â†’ âœ… 7/7 passed
  - Details: `RobotsParser` í´ë˜ìŠ¤ (robots.txt íŒŒì‹± ê¸°ëŠ¥)

**ğŸ”µ REFACTOR (TDD-3.1)**
- [x] **Task 3.1R**: robots.txt íŒŒì‹± ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/robots_parser.py`
  - Goal: ì½”ë“œ í’ˆì§ˆ ê°œì„  â†’ âœ… 7/7 passed (ruff format ì ìš©)

**ğŸ”´ RED: Write Failing Tests First (TDD-3.2: URL í—ˆìš© íŒë‹¨)**
- [x] **Test 3.2**: URL í—ˆìš©/ì°¨ë‹¨ íŒë‹¨ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_robots_parser.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… AttributeError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ê·œì¹™ ì—†ìŒ â†’ í—ˆìš©
    - Disallow ê²½ë¡œ â†’ ì°¨ë‹¨
    - Allow ê²½ë¡œ â†’ í—ˆìš©
    - ì™€ì¼ë“œì¹´ë“œ(*) íŒ¨í„´
    - íŠ¹ì • User-agent ê·œì¹™

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-3.2)**
- [x] **Task 3.2**: URL í—ˆìš© íŒë‹¨ ë©”ì„œë“œ êµ¬í˜„
  - File(s): `src/eazy/crawler/robots_parser.py`
  - Goal: Test 3.2 í†µê³¼ â†’ âœ… 12/12 passed
  - Details: `is_allowed(url: str, user_agent: str) -> bool` êµ¬í˜„

**ğŸ”µ REFACTOR (TDD-3.2)**
- [x] **Task 3.2R**: URL í—ˆìš© íŒë‹¨ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/robots_parser.py`
  - Goal: URL í—ˆìš© íŒë‹¨ ë¡œì§ ìµœì í™” â†’ âœ… 12/12 passed (_match_pattern ê°„ì†Œí™”)

#### Commits
```
test(crawler): add failing tests for robots.txt parsing
feat(crawler): implement robots.txt parser
refactor(crawler): improve robots parser code quality
test(crawler): add failing tests for URL allow/disallow check
feat(crawler): implement URL permission checking
refactor(crawler): optimize URL permission logic
```

#### Quality Gate âœ‹

**âš ï¸ STOP: Phase 5 ì§„í–‰ ì „ ëª¨ë“  ì²´í¬ í•­ëª©ì„ í†µê³¼í•´ì•¼ í•¨**

**TDD Compliance** (CRITICAL):
- [x] **Red Phase**: í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ê³  ì‹¤íŒ¨ í™•ì¸ (ModuleNotFoundError/AttributeError)
- [x] **Green Phase**: ìµœì†Œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼ (12/12 passed)
- [x] **Refactor Phase**: í…ŒìŠ¤íŠ¸ í†µê³¼ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ ê°œì„ 
- [x] **Coverage Check**: ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (93%, ëª©í‘œ 80%+)
  ```bash
  # ì»¤ë²„ë¦¬ì§€ í™•ì¸
  uv run pytest tests/unit/crawler/test_robots_parser.py --cov=eazy.crawler.robots_parser --cov-report=term-missing
  # Result: 74 statements, 5 missed, 93% coverage
  ```

**Build & Tests**:
- [x] **Build**: í”„ë¡œì íŠ¸ ë¹Œë“œ/ì»´íŒŒì¼ ì—ëŸ¬ ì—†ìŒ
- [x] **All Tests Pass**: 100% í…ŒìŠ¤íŠ¸ í†µê³¼ (74/74 ì „ì²´, 12/12 robots_parser, ìŠ¤í‚µ ì—†ìŒ)
- [x] **Test Performance**: í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ 0.09ì´ˆ ì™„ë£Œ
- [x] **No Flaky Tests**: í…ŒìŠ¤íŠ¸ ì¼ê´€ í†µê³¼ í™•ì¸

**Code Quality**:
- [x] **Linting**: ë¦°íŒ… ì—ëŸ¬/ê²½ê³  ì—†ìŒ (ruff check passed)
- [x] **Formatting**: í”„ë¡œì íŠ¸ í‘œì¤€ì— ë§ëŠ” í¬ë§·íŒ… (ruff format passed)
- [x] **Type Safety**: ëª¨ë“  í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ íƒ€ì… íŒíŠ¸ ì ìš©
- [x] **Static Analysis**: ì •ì  ë¶„ì„ ë„êµ¬ ì‹¬ê° ì´ìŠˆ ì—†ìŒ

**Security & Performance**:
- [x] **Dependencies**: ì•Œë ¤ì§„ ë³´ì•ˆ ì·¨ì•½ì  ì—†ìŒ (stdlibë§Œ ì‚¬ìš©: re, urllib.parse)
- [x] **Performance**: ì„±ëŠ¥ ì €í•˜ ì—†ìŒ
- [x] **Memory**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜/ìì› ì´ìŠˆ ì—†ìŒ
- [x] **Error Handling**: ë¹ˆ robots.txt, ì˜ëª»ëœ Crawl-delay ë“± ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬

**Documentation**:
- [x] **Code Comments**: Google ìŠ¤íƒ€ì¼ docstring ì¶”ê°€
- [x] **API Docs**: ê³µê°œ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì„œí™” (ëª¨ë“  ë©”ì„œë“œ docstring)
- [x] **README**: N/A (Phase 4)

**Manual Testing**:
- [x] **Functionality**: ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸
- [x] **Edge Cases**: ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [x] **Error States**: ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ

**Validation Commands**:
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest tests/unit/crawler/test_robots_parser.py -v

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
uv run pytest tests/unit/crawler/test_robots_parser.py --cov=eazy.crawler.robots_parser --cov-report=term-missing

# ë¦°íŒ…
uv run ruff check src/eazy/crawler/robots_parser.py tests/unit/crawler/test_robots_parser.py

# í¬ë§·íŒ… í™•ì¸
uv run ruff format --check src/eazy/crawler/robots_parser.py tests/unit/crawler/test_robots_parser.py

# ì „ì²´ íšŒê·€ í…ŒìŠ¤íŠ¸
uv run pytest --cov=src/eazy --cov-report=term-missing
```

**Manual Test Checklist**:
- [x] ì‹¤ì œ robots.txt ì˜ˆì‹œ íŒŒì‹± ê²°ê³¼ í™•ì¸
- [x] Googlebot vs * User-agent ê·œì¹™ ë¶„ë¦¬ í™•ì¸
- [x] ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ ë§¤ì¹­ ì •í™•ì„± í™•ì¸

---

### Phase 5: HTTP Client
**Goal**: ë¹„ë™ê¸° HTTP ìš”ì²­, ì¬ì‹œë„, ë”œë ˆì´, ì—ëŸ¬ ì²˜ë¦¬
**Status**: âœ… Complete

#### Tasks

**ğŸ”´ RED: Write Failing Tests First (TDD-4.1: í˜ì´ì§€ ìš”ì²­)**
- [x] **Test 4.1**: HTTP í´ë¼ì´ì–¸íŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± (respx ëª¨í‚¹)
  - File(s): `tests/unit/crawler/test_http_client.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ModuleNotFoundError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - 200 ì„±ê³µ ì‘ë‹µ ì²˜ë¦¬
    - 404 ì—ëŸ¬ ì²˜ë¦¬
    - íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
    - ë¦¬ë‹¤ì´ë ‰íŠ¸ ì¶”ì 
    - ì—°ê²° ì—ëŸ¬ ì²˜ë¦¬
    - ì¬ì‹œë„ ë¡œì§ (ìµœëŒ€ 3íšŒ)
    - ìš”ì²­ ê°„ ë”œë ˆì´
    - ì»¤ìŠ¤í…€ User-Agent í—¤ë”

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-4.1)**
- [x] **Task 4.1**: HttpClient í´ë˜ìŠ¤ êµ¬í˜„
  - File(s): `src/eazy/crawler/http_client.py`
  - Goal: Test 4.1 í†µê³¼ â†’ âœ… 8/8 passed
  - Details: `HttpClient` í´ë˜ìŠ¤ (httpx.AsyncClient ê¸°ë°˜, ì¬ì‹œë„/ë”œë ˆì´/ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)

**ğŸ”µ REFACTOR (TDD-4.1)**
- [x] **Task 4.1R**: HTTP í´ë¼ì´ì–¸íŠ¸ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/http_client.py`
  - Goal: ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ ê°œì„ , ì½”ë“œ í’ˆì§ˆ í–¥ìƒ â†’ âœ… 8/8 passed (import ì •ë ¬, ruff format ì ìš©)

#### Commits
```
test(crawler): add failing tests for HTTP client
feat(crawler): implement async HTTP client with retry
refactor(crawler): fix HTTP client test import ordering
```

#### Quality Gate âœ‹

**âš ï¸ STOP: Phase 6 ì§„í–‰ ì „ ëª¨ë“  ì²´í¬ í•­ëª©ì„ í†µê³¼í•´ì•¼ í•¨**

**TDD Compliance** (CRITICAL):
- [x] **Red Phase**: í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ê³  ì‹¤íŒ¨ í™•ì¸ (ModuleNotFoundError)
- [x] **Green Phase**: ìµœì†Œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼ (8/8 passed)
- [x] **Refactor Phase**: í…ŒìŠ¤íŠ¸ í†µê³¼ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ ê°œì„  (import ì •ë ¬)
- [x] **Coverage Check**: ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (96%, ëª©í‘œ 80%+)
  ```bash
  # ì»¤ë²„ë¦¬ì§€ í™•ì¸
  uv run pytest tests/unit/crawler/test_http_client.py --cov=eazy.crawler.http_client --cov-report=term-missing
  # Result: 53 statements, 2 missed, 96% coverage
  ```

**Build & Tests**:
- [x] **Build**: í”„ë¡œì íŠ¸ ë¹Œë“œ/ì»´íŒŒì¼ ì—ëŸ¬ ì—†ìŒ
- [x] **All Tests Pass**: 100% í…ŒìŠ¤íŠ¸ í†µê³¼ (82/82 ì „ì²´, 8/8 http_client, ìŠ¤í‚µ ì—†ìŒ)
- [x] **Test Performance**: í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ 0.13ì´ˆ ì™„ë£Œ
- [x] **No Flaky Tests**: í…ŒìŠ¤íŠ¸ ì¼ê´€ í†µê³¼ í™•ì¸

**Code Quality**:
- [x] **Linting**: ë¦°íŒ… ì—ëŸ¬/ê²½ê³  ì—†ìŒ (ruff check passed)
- [x] **Formatting**: í”„ë¡œì íŠ¸ í‘œì¤€ì— ë§ëŠ” í¬ë§·íŒ… (ruff format passed)
- [x] **Type Safety**: ëª¨ë“  í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ íƒ€ì… íŒíŠ¸ ì ìš©
- [x] **Static Analysis**: ì •ì  ë¶„ì„ ë„êµ¬ ì‹¬ê° ì´ìŠˆ ì—†ìŒ

**Security & Performance**:
- [x] **Dependencies**: ì•Œë ¤ì§„ ë³´ì•ˆ ì·¨ì•½ì  ì—†ìŒ (httpx ì‚¬ìš©)
- [x] **Performance**: ì„±ëŠ¥ ì €í•˜ ì—†ìŒ (monotonic clock ê¸°ë°˜ ë”œë ˆì´)
- [x] **Memory**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜/ìì› ì´ìŠˆ ì—†ìŒ (async context managerë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒëª…ì£¼ê¸° ê´€ë¦¬)
- [x] **Error Handling**: 5xx/timeout/connect ì—ëŸ¬ ì¬ì‹œë„, 4xx ì¦‰ì‹œ ë°˜í™˜, error í•„ë“œë¡œ ì—ëŸ¬ ì „ë‹¬

**Documentation**:
- [x] **Code Comments**: Google ìŠ¤íƒ€ì¼ docstring ì¶”ê°€
- [x] **API Docs**: ê³µê°œ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì„œí™” (HttpResponse, HttpClient, fetch ë©”ì„œë“œ)
- [x] **README**: N/A (Phase 5)

**Manual Testing**:
- [x] **Functionality**: ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸
- [x] **Edge Cases**: ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [x] **Error States**: ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ

**Validation Commands**:
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest tests/unit/crawler/test_http_client.py -v

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
uv run pytest tests/unit/crawler/test_http_client.py --cov=eazy.crawler.http_client --cov-report=term-missing

# ë¦°íŒ…
uv run ruff check src/eazy/crawler/http_client.py tests/unit/crawler/test_http_client.py

# í¬ë§·íŒ… í™•ì¸
uv run ruff format --check src/eazy/crawler/http_client.py tests/unit/crawler/test_http_client.py

# ì „ì²´ íšŒê·€ í…ŒìŠ¤íŠ¸
uv run pytest --cov=src/eazy --cov-report=term-missing
```

**Manual Test Checklist**:
- [x] respx ëª¨í‚¹ìœ¼ë¡œ ë‹¤ì–‘í•œ HTTP ìƒíƒœ ì½”ë“œ ì‘ë‹µ í™•ì¸
- [x] ì¬ì‹œë„ ë¡œì§ì´ ì •í™•íˆ 3íšŒê¹Œì§€ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
- [x] íƒ€ì„ì•„ì›ƒ ì„¤ì •ì´ ì˜¬ë°”ë¥´ê²Œ ì ìš©ë˜ëŠ”ì§€ í™•ì¸

---

### Phase 6: Sitemap & Exporter
**Goal**: í¬ë¡¤ë§ ê²°ê³¼ ì‚¬ì´íŠ¸ë§µ êµ¬ì¡°í™” ë° JSON ì¶œë ¥
**Status**: âœ… Complete

#### Tasks

**ğŸ”´ RED: Write Failing Tests First (TDD-5.1: ì‚¬ì´íŠ¸ë§µ êµ¬ì¡°)**
- [x] **Test 5.1**: ì‚¬ì´íŠ¸ë§µ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_sitemap.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ModuleNotFoundError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - í˜ì´ì§€ ì¶”ê°€ ë° ì¡°íšŒ
    - íŠ¸ë¦¬ êµ¬ì¡° (ë¶€ëª¨-ìì‹ ê´€ê³„)
    - ê¹Šì´(depth) ì¶”ì 
    - dict ë³€í™˜
    - í†µê³„ (ì´ í˜ì´ì§€ ìˆ˜, ì´ ë§í¬ ìˆ˜, ì´ í¼ ìˆ˜ ë“±)

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-5.1)**
- [x] **Task 5.1**: Sitemap í´ë˜ìŠ¤ êµ¬í˜„
  - File(s): `src/eazy/crawler/sitemap.py`
  - Goal: Test 5.1 í†µê³¼ â†’ âœ… 7/7 passed
  - Details: `Sitemap` í´ë˜ìŠ¤ (í˜ì´ì§€ ì¶”ê°€, íŠ¸ë¦¬ êµ¬ì¡°, í†µê³„ ê¸°ëŠ¥)

**ğŸ”µ REFACTOR (TDD-5.1)**
- [x] **Task 5.1R**: ì‚¬ì´íŠ¸ë§µ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/sitemap.py`
  - Goal: ì½”ë“œ í’ˆì§ˆ ê°œì„  â†’ âœ… 7/7 passed (ruff format ì ìš©)

**ğŸ”´ RED: Write Failing Tests First (TDD-5.2: ê²°ê³¼ ì¶œë ¥)**
- [x] **Test 5.2**: ê²°ê³¼ ì¶œë ¥(Exporter) ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/unit/crawler/test_exporter.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (êµ¬í˜„ ë¯¸ì¡´ì¬) â†’ âœ… ModuleNotFoundError í™•ì¸
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - JSON ë¬¸ìì—´ ì¶œë ¥
    - íŒŒì¼ ì €ì¥ (tmp_path í™œìš©)
    - URL ëª©ë¡ í¬í•¨ í™•ì¸
    - íŒŒë¼ë¯¸í„° ëª©ë¡ í¬í•¨ í™•ì¸
    - ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡ í¬í•¨ í™•ì¸
    - í¼ ë°ì´í„° í¬í•¨ í™•ì¸
    - ë©”íƒ€ë°ì´í„°(íƒ€ì„ìŠ¤íƒ¬í”„, ì„¤ì • ë“±) í¬í•¨ í™•ì¸

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-5.2)**
- [x] **Task 5.2**: CrawlResultExporter í´ë˜ìŠ¤ êµ¬í˜„
  - File(s): `src/eazy/crawler/exporter.py`
  - Goal: Test 5.2 í†µê³¼ â†’ âœ… 7/7 passed
  - Details: `CrawlResultExporter` í´ë˜ìŠ¤ (JSON ì¶œë ¥, íŒŒì¼ ì €ì¥ ê¸°ëŠ¥)

**ğŸ”µ REFACTOR (TDD-5.2)**
- [x] **Task 5.2R**: ê²°ê³¼ ì¶œë ¥ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/exporter.py`
  - Goal: ì¶œë ¥ í¬ë§· ìµœì í™” â†’ âœ… 7/7 passed (ì´ë¯¸ ìµœì  ìƒíƒœ)

#### Commits
```
test(crawler): add failing tests for sitemap structure
feat(crawler): implement sitemap class
refactor(crawler): improve sitemap code quality
test(crawler): add failing tests for result exporter
feat(crawler): implement crawl result exporter
refactor(crawler): optimize exporter output format
```

#### Quality Gate âœ‹

**âš ï¸ STOP: Phase 7 ì§„í–‰ ì „ ëª¨ë“  ì²´í¬ í•­ëª©ì„ í†µê³¼í•´ì•¼ í•¨**

**TDD Compliance** (CRITICAL):
- [x] **Red Phase**: í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ê³  ì‹¤íŒ¨ í™•ì¸ (ModuleNotFoundError)
- [x] **Green Phase**: ìµœì†Œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼ (14/14 passed)
- [x] **Refactor Phase**: í…ŒìŠ¤íŠ¸ í†µê³¼ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ ê°œì„  (ruff format ì ìš©)
- [x] **Coverage Check**: ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± (sitemap 100%, exporter 100%, ëª©í‘œ 80%+)
  ```bash
  # ì»¤ë²„ë¦¬ì§€ í™•ì¸
  uv run pytest tests/unit/crawler/test_sitemap.py --cov=eazy.crawler.sitemap --cov-report=term-missing
  # Result: 21 statements, 0 missed, 100% coverage
  uv run pytest tests/unit/crawler/test_exporter.py --cov=eazy.crawler.exporter --cov-report=term-missing
  # Result: 10 statements, 0 missed, 100% coverage
  ```

**Build & Tests**:
- [x] **Build**: í”„ë¡œì íŠ¸ ë¹Œë“œ/ì»´íŒŒì¼ ì—ëŸ¬ ì—†ìŒ
- [x] **All Tests Pass**: 100% í…ŒìŠ¤íŠ¸ í†µê³¼ (96/96 ì „ì²´, 14/14 sitemap+exporter, ìŠ¤í‚µ ì—†ìŒ)
- [x] **Test Performance**: í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ 0.12ì´ˆ ì™„ë£Œ
- [x] **No Flaky Tests**: í…ŒìŠ¤íŠ¸ ì¼ê´€ í†µê³¼ í™•ì¸

**Code Quality**:
- [x] **Linting**: ë¦°íŒ… ì—ëŸ¬/ê²½ê³  ì—†ìŒ (ruff check passed)
- [x] **Formatting**: í”„ë¡œì íŠ¸ í‘œì¤€ì— ë§ëŠ” í¬ë§·íŒ… (ruff format passed)
- [x] **Type Safety**: ëª¨ë“  í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ íƒ€ì… íŒíŠ¸ ì ìš©
- [x] **Static Analysis**: ì •ì  ë¶„ì„ ë„êµ¬ ì‹¬ê° ì´ìŠˆ ì—†ìŒ

**Security & Performance**:
- [x] **Dependencies**: ì•Œë ¤ì§„ ë³´ì•ˆ ì·¨ì•½ì  ì—†ìŒ (stdlib + pydanticë§Œ ì‚¬ìš©)
- [x] **Performance**: ì„±ëŠ¥ ì €í•˜ ì—†ìŒ (dict ê¸°ë°˜ O(1) ì¡°íšŒ)
- [x] **Memory**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜/ìì› ì´ìŠˆ ì—†ìŒ
- [x] **Error Handling**: get_page None ë°˜í™˜, get_children ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

**Documentation**:
- [x] **Code Comments**: Google ìŠ¤íƒ€ì¼ docstring ì¶”ê°€
- [x] **API Docs**: ê³µê°œ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì„œí™” (Sitemap, CrawlResultExporter ëª¨ë“  ë©”ì„œë“œ)
- [x] **README**: N/A (Phase 6)

**Manual Testing**:
- [x] **Functionality**: ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸
- [x] **Edge Cases**: ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [x] **Error States**: ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ

**Validation Commands**:
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest tests/unit/crawler/test_sitemap.py tests/unit/crawler/test_exporter.py -v

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
uv run pytest tests/unit/crawler/test_sitemap.py --cov=eazy.crawler.sitemap --cov-report=term-missing
uv run pytest tests/unit/crawler/test_exporter.py --cov=eazy.crawler.exporter --cov-report=term-missing

# ë¦°íŒ…
uv run ruff check src/eazy/crawler/sitemap.py src/eazy/crawler/exporter.py tests/unit/crawler/test_sitemap.py tests/unit/crawler/test_exporter.py

# í¬ë§·íŒ… í™•ì¸
uv run ruff format --check src/eazy/crawler/sitemap.py src/eazy/crawler/exporter.py tests/unit/crawler/test_sitemap.py tests/unit/crawler/test_exporter.py

# ì „ì²´ íšŒê·€ í…ŒìŠ¤íŠ¸
uv run pytest --cov=src/eazy --cov-report=term-missing
```

**Manual Test Checklist**:
- [x] Sitemap íŠ¸ë¦¬ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥¸ ë¶€ëª¨-ìì‹ ê´€ê³„ì¸ì§€ í™•ì¸
- [x] JSON ì¶œë ¥ ìŠ¤í‚¤ë§ˆê°€ PRD ìš”êµ¬ì‚¬í•­ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸
- [x] íŒŒì¼ ì €ì¥ í›„ ì¬ë¡œë“œ ì‹œ ë°ì´í„° ì¼ê´€ì„± í™•ì¸

---

### Phase 7: Crawler Engine í†µí•©
**Goal**: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•œ í¬ë¡¤ë§ ì—”ì§„ ì™„ì„±
**Status**: â³ Pending

#### Tasks

**ğŸ”´ RED: Write Failing Tests First (TDD-6.1: ê¸°ë³¸ í¬ë¡¤ë§)**
- [ ] **Test 6.1**: ê¸°ë³¸ í¬ë¡¤ë§ í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/integration/crawler/test_crawler_engine.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (ì—”ì§„ ë¯¸êµ¬í˜„)
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ë‹¨ì¼ í˜ì´ì§€ í¬ë¡¤ë§
    - ë§í¬ ì¶”ì  (ë°œê²¬ëœ ë§í¬ â†’ í›„ì† í¬ë¡¤ë§)
    - ì¤‘ë³µ URL ë°©ì§€
    - ë°©ë¬¸ ê¸°ë¡ ìœ ì§€

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-6.1)**
- [ ] **Task 6.1**: CrawlerEngine ê¸°ë³¸ êµ¬í˜„
  - File(s): `src/eazy/crawler/engine.py`
  - Goal: Test 6.1 í†µê³¼
  - Details: `CrawlerEngine.crawl()` ë©”ì„œë“œ ê¸°ë³¸ êµ¬í˜„ (ë‹¨ì¼ í˜ì´ì§€ í¬ë¡¤ë§ + ë§í¬ ì¶”ì )

**ğŸ”µ REFACTOR (TDD-6.1)**
- [ ] **Task 6.1R**: í¬ë¡¤ë§ ì—”ì§„ êµ¬ì¡° ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/engine.py`
  - Goal: ì—”ì§„ êµ¬ì¡° ê°œì„ 

**ğŸ”´ RED: Write Failing Tests First (TDD-6.2: í¬ë¡¤ë§ ì„¤ì •)**
- [ ] **Test 6.2**: í¬ë¡¤ë§ ì„¤ì • ì ìš© í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/integration/crawler/test_crawler_engine.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (ì„¤ì • ì ìš© ë¯¸êµ¬í˜„)
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ìµœëŒ€ ê¹Šì´ ì œí•œ
    - ë„ë©”ì¸ ìŠ¤ì½”í”„ ì ìš©
    - robots.txt ì¤€ìˆ˜
    - ìµœëŒ€ í˜ì´ì§€ ìˆ˜ ì œí•œ
    - ì œì™¸ íŒ¨í„´ ì ìš©

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-6.2)**
- [ ] **Task 6.2**: í¬ë¡¤ë§ ì„¤ì • ì ìš© ë¡œì§ êµ¬í˜„
  - File(s): `src/eazy/crawler/engine.py`
  - Goal: Test 6.2 í†µê³¼
  - Details: CrawlConfig ê¸°ë°˜ ì„¤ì • ì ìš© (ê¹Šì´ ì œí•œ, ìŠ¤ì½”í”„, robots.txt, í˜ì´ì§€ ìˆ˜ ì œí•œ, ì œì™¸ íŒ¨í„´)

**ğŸ”µ REFACTOR (TDD-6.2)**
- [ ] **Task 6.2R**: ì„¤ì • ë¡œì§ ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/engine.py`
  - Goal: ì„¤ì • ì ìš© ë¡œì§ ìµœì í™”

**ğŸ”´ RED: Write Failing Tests First (TDD-6.3: ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸)**
- [ ] **Test 6.3**: ì „ì²´ ì›Œí¬í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
  - File(s): `tests/integration/crawler/test_crawler_engine.py`
  - Expected: í…ŒìŠ¤íŠ¸ FAIL (ì „ì²´ í†µí•© ë¯¸ì™„ì„±)
  - Details: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
    - ì „ì²´ ì›Œí¬í”Œë¡œìš° (URL ì…ë ¥ â†’ í¬ë¡¤ë§ â†’ JSON ì¶œë ¥)
    - robots.txt í¬í•¨ ì‹œë‚˜ë¦¬ì˜¤
    - ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦
    - ì—ëŸ¬ í•¸ë“¤ë§ (ì¡´ì¬í•˜ì§€ ì•ŠëŠ” URL, ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬)

**ğŸŸ¢ GREEN: Implement to Make Tests Pass (TDD-6.3)**
- [ ] **Task 6.3**: ì „ì²´ í†µí•© ì™„ì„±
  - File(s): `src/eazy/crawler/engine.py`
  - Goal: Test 6.3 í†µê³¼
  - Details: ì „ì²´ ì›Œí¬í”Œë¡œìš° í†µí•© (URL ì…ë ¥ â†’ í¬ë¡¤ë§ â†’ Sitemap êµ¬ì¶• â†’ JSON ì¶œë ¥)

**ğŸ”µ REFACTOR (TDD-6.3)**
- [ ] **Task 6.3R**: ìµœì¢… ë¦¬íŒ©í† ë§
  - Files: `src/eazy/crawler/engine.py` ë° ê´€ë ¨ ëª¨ë“ˆ ì „ì²´
  - Goal: ìµœì¢… ì½”ë“œ í’ˆì§ˆ ê°œì„ 
  - Checklist:
    - [ ] ì¤‘ë³µ ì½”ë“œ ì œê±° (DRY ì›ì¹™)
    - [ ] ë„¤ì´ë° ëª…í™•ì„± ê°œì„ 
    - [ ] ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ ì¶”ì¶œ
    - [ ] ì¸ë¼ì¸ ë¬¸ì„œí™” ì¶”ê°€
    - [ ] ì„±ëŠ¥ ìµœì í™” (í•„ìš” ì‹œ)

#### Commits
```
test(crawler): add failing tests for basic crawling
feat(crawler): implement basic crawler engine
refactor(crawler): improve crawler engine structure
test(crawler): add failing tests for crawl configuration
feat(crawler): implement crawl configuration handling
refactor(crawler): optimize configuration logic
test(crawler): add failing integration tests for full workflow
feat(crawler): complete full crawling workflow integration
refactor(crawler): final code quality improvements
```

#### Quality Gate âœ‹

**âš ï¸ STOP: ìµœì¢… ì™„ë£Œ ì„ ì–¸ ì „ ëª¨ë“  ì²´í¬ í•­ëª©ì„ í†µê³¼í•´ì•¼ í•¨**

**TDD Compliance** (CRITICAL):
- [ ] **Red Phase**: í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•˜ê³  ì‹¤íŒ¨ í™•ì¸
- [ ] **Green Phase**: ìµœì†Œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] **Refactor Phase**: í…ŒìŠ¤íŠ¸ í†µê³¼ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ ê°œì„ 
- [ ] **Coverage Check**: ì „ì²´ ì»¤ë²„ë¦¬ì§€ 80%+ ë‹¬ì„±

**Build & Tests**:
- [ ] **Build**: í”„ë¡œì íŠ¸ ë¹Œë“œ/ì»´íŒŒì¼ ì—ëŸ¬ ì—†ìŒ
- [ ] **All Tests Pass**: 100% í…ŒìŠ¤íŠ¸ í†µê³¼ (ìŠ¤í‚µ ì—†ìŒ)
- [ ] **Test Performance**: í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ í—ˆìš© ì‹œê°„ ë‚´ ì™„ë£Œ
- [ ] **No Flaky Tests**: í…ŒìŠ¤íŠ¸ 3íšŒ ì´ìƒ ì¼ê´€ í†µê³¼

**Code Quality**:
- [ ] **Linting**: ë¦°íŒ… ì—ëŸ¬/ê²½ê³  ì—†ìŒ
- [ ] **Formatting**: í”„ë¡œì íŠ¸ í‘œì¤€ì— ë§ëŠ” í¬ë§·íŒ…
- [ ] **Type Safety**: íƒ€ì… ì²´í¬ í†µê³¼ (í•´ë‹¹ ì‹œ)
- [ ] **Static Analysis**: ì •ì  ë¶„ì„ ë„êµ¬ ì‹¬ê° ì´ìŠˆ ì—†ìŒ

**Security & Performance**:
- [ ] **Dependencies**: ì•Œë ¤ì§„ ë³´ì•ˆ ì·¨ì•½ì  ì—†ìŒ
- [ ] **Performance**: ì„±ëŠ¥ ì €í•˜ ì—†ìŒ
- [ ] **Memory**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜/ìì› ì´ìŠˆ ì—†ìŒ
- [ ] **Error Handling**: ì ì ˆí•œ ì—ëŸ¬ ì²˜ë¦¬ êµ¬í˜„

**Documentation**:
- [ ] **Code Comments**: ë³µì¡í•œ ë¡œì§ ë¬¸ì„œí™”
- [ ] **API Docs**: ê³µê°œ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì„œí™”
- [ ] **README**: í•„ìš” ì‹œ ì‚¬ìš© ë°©ë²• ì—…ë°ì´íŠ¸

**Manual Testing**:
- [ ] **Functionality**: ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸
- [ ] **Edge Cases**: ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] **Error States**: ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ

**Validation Commands**: Phase 1 ê²€ì¦ ì»¤ë§¨ë“œ ì°¸ì¡°

**Manual Test Checklist**:
- [ ] respxë¡œ ë©€í‹°í˜ì´ì§€ ì‚¬ì´íŠ¸ ëª¨í‚¹ í›„ ì „ì²´ í¬ë¡¤ë§ í™•ì¸
- [ ] ê¹Šì´ ì œí•œì´ ì •í™•íˆ ì ìš©ë˜ëŠ”ì§€ í™•ì¸
- [ ] JSON ì¶œë ¥ì— ëª¨ë“  í•„ìˆ˜ í•„ë“œ(URLs, params, endpoints, forms, metadata) í¬í•¨ í™•ì¸
- [ ] robots.txt ì°¨ë‹¨ ê²½ë¡œê°€ í¬ë¡¤ë§ì—ì„œ ì œì™¸ë˜ëŠ”ì§€ í™•ì¸

---

## âš ï¸ Risk Assessment

| Risk | Probability | Impact | Mitigation Strategy |
|------|-------------|--------|---------------------|
| ì •ê·œì‹ìœ¼ë¡œ ë³µì¡í•œ HTML íŒŒì‹± ì‹¤íŒ¨ | Medium | Medium | ì£¼ìš” íŒ¨í„´ ìœ„ì£¼ë¡œ ë²”ìœ„ í•œì •, Phase 2ì—ì„œ edge case ì¶©ë¶„íˆ í…ŒìŠ¤íŠ¸ |
| httpx/respx ë²„ì „ í˜¸í™˜ì„± ì´ìŠˆ | Low | High | pyproject.tomlì— ë²„ì „ ê³ ì •, CIì—ì„œ ê²€ì¦ |
| ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ë¶ˆì•ˆì • (flaky) | Medium | Low | pytest-asyncio strict mode, íƒ€ì„ì•„ì›ƒ ì—¬ìœ  ì„¤ì • |
| í¬ë¡¤ë§ ì—”ì§„ í†µí•© ì‹œ ì»´í¬ë„ŒíŠ¸ ê°„ ì¸í„°í˜ì´ìŠ¤ ë¶ˆì¼ì¹˜ | Low | High | Pydantic ëª¨ë¸ë¡œ ì¸í„°í˜ì´ìŠ¤ ê³„ì•½ ë³´ì¥, Phase 1ì—ì„œ ëª¨ë¸ í™•ì • |

---

## ğŸ”„ Rollback Strategy

### If Phase 1 Fails
**ë³µì› ë‹¨ê³„**:
- `git checkout main` ìœ¼ë¡œ ë³µì›
- ë¸Œëœì¹˜ ì‚­ì œ: `git branch -D feature/req-001-regex-crawler`

### If Phase 2~6 Fails
**ë³µì› ë‹¨ê³„**:
- í•´ë‹¹ Phase ì§ì „ ì»¤ë°‹ìœ¼ë¡œ ë³µì›: `git reset --soft HEAD~N`
- ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ í›„ ì¬ì‹œë„

### If Phase 7 Fails
**ë³µì› ë‹¨ê³„**:
- Phase 6 ì™„ë£Œ ìƒíƒœë¡œ ë³µì›
- í†µí•© ë¡œì§ë§Œ ì¬ì‘ì„±

---

## ğŸ“Š Progress Tracking

### Completion Status
- **Phase 1**: âœ… 100% (2026-02-12 ì™„ë£Œ)
- **Phase 2**: âœ… 100% (2026-02-12 ì™„ë£Œ)
- **Phase 3**: âœ… 100% (2026-02-12 ì™„ë£Œ)
- **Phase 4**: âœ… 100% (2026-02-12 ì™„ë£Œ)
- **Phase 5**: âœ… 100% (2026-02-12 ì™„ë£Œ)
- **Phase 6**: âœ… 100% (2026-02-13 ì™„ë£Œ)
- **Phase 7**: â³ 0%

**Overall Progress**: ~86% complete (6/7 phases)

### Time Tracking
| Phase | Estimated | Actual | Variance |
|-------|-----------|--------|----------|
| Phase 1 | - | 2026-02-12 | - |
| Phase 2 | - | 2026-02-12 | - |
| Phase 3 | - | 2026-02-12 | - |
| Phase 4 | - | 2026-02-12 | - |
| Phase 5 | - | 2026-02-12 | - |
| Phase 6 | - | 2026-02-13 | - |
| Phase 7 | - | - | - |
| **Total** | - | - | - |

---

## ğŸ“ Notes & Learnings

### Implementation Notes
- Pydantic v2ì˜ `ConfigDict(frozen=True)`ë¥¼ CrawlConfigì— ì ìš©í•˜ì—¬ ì„¤ì • ë¶ˆë³€ì„± ë³´ì¥
- `Field(default_factory=list)` íŒ¨í„´ìœ¼ë¡œ mutable default ë¬¸ì œ ë°©ì§€
- Python 3.14 í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ (3.12+ í˜¸í™˜ í™•ì¸)
- Google ìŠ¤íƒ€ì¼ docstringìœ¼ë¡œ Attributes ì„¹ì…˜ ì¶”ê°€ (CLAUDE.md ì»¨ë²¤ì…˜)
- `max_depth="not_a_number"` ì…ë ¥ ì‹œ Pydantic v2ê°€ ì •ìƒì ìœ¼ë¡œ ValidationError ë°œìƒ í™•ì¸
- (Phase 2) ëª¨ë“  ì •ê·œì‹ì„ ëª¨ë“ˆ ë ˆë²¨ `re.compile()` ìƒìˆ˜ë¡œ ì •ì˜í•˜ì—¬ ë°˜ë³µ í˜¸ì¶œ ì‹œ ì„±ëŠ¥ ìµœì í™”
- (Phase 2) 4ê°œ ìˆœìˆ˜ í•¨ìˆ˜ë¡œ êµ¬í˜„: extract_links, extract_forms, extract_buttons, extract_api_endpoints
- (Phase 2) Phase 1 Pydantic ëª¨ë¸(FormData, ButtonInfo, EndpointInfo) ì¬ì‚¬ìš©ìœ¼ë¡œ íƒ€ì… ì•ˆì „ì„± í™•ë³´
- (Phase 2) 25ê°œ í…ŒìŠ¤íŠ¸, regex_parser.py 100% ì»¤ë²„ë¦¬ì§€ ë‹¬ì„±
- (Phase 2) `str.startswith(tuple)` íŒ¨í„´ìœ¼ë¡œ ë‹¤ì¤‘ í”„ë¡œí† ì½œ í•„í„°ë§ ê°„ê²°í•˜ê²Œ êµ¬í˜„
- (Phase 3) 3ê°œ ìˆœìˆ˜ í•¨ìˆ˜ë¡œ êµ¬í˜„: resolve_url, normalize_url, is_in_scope
- (Phase 3) Python stdlibë§Œ ì‚¬ìš© (urllib.parse, fnmatch) â€” ì™¸ë¶€ ì˜ì¡´ì„± ì—†ìŒ
- (Phase 3) CrawlConfig ëª¨ë¸ ì¬ì‚¬ìš©ìœ¼ë¡œ is_in_scopeì—ì„œ íƒ€ì… ì•ˆì „ì„± í™•ë³´
- (Phase 3) 20ê°œ í…ŒìŠ¤íŠ¸, url_resolver.py 96% ì»¤ë²„ë¦¬ì§€ ë‹¬ì„±
- (Phase 3) `--cov` ê²½ë¡œëŠ” íŒ¨í‚¤ì§€ ì´ë¦„ (`eazy.crawler.url_resolver`) ì‚¬ìš©í•´ì•¼ í•¨ (`src/` ì ‘ë‘ì‚¬ X)
- (Phase 4) í´ë˜ìŠ¤ ê¸°ë°˜ êµ¬í˜„ (RobotsParser) â€” íŒŒì‹± ê²°ê³¼ ìƒíƒœ ìœ ì§€ í•„ìš”
- (Phase 4) stdlibë§Œ ì‚¬ìš© (re, urllib.parse) â€” ì™¸ë¶€ ì˜ì¡´ì„± ì—†ìŒ
- (Phase 4) robots.txt íŒ¨í„´ì„ ì •ê·œì‹ìœ¼ë¡œ ë³€í™˜: `*` â†’ `.*`, `$` â†’ `$`, ë‚˜ë¨¸ì§€ re.escape
- (Phase 4) ìš°ì„ ìˆœìœ„: ë” ê¸´(êµ¬ì²´ì ) íŒ¨í„´ ìš°ì„ , ê°™ì€ ê¸¸ì´ë©´ Allow ìš°ì„  (Google í‘œì¤€)
- (Phase 4) 12ê°œ í…ŒìŠ¤íŠ¸, robots_parser.py 93% ì»¤ë²„ë¦¬ì§€ ë‹¬ì„±
- (Phase 5) í´ë˜ìŠ¤ ê¸°ë°˜ êµ¬í˜„ (HttpClient) â€” async context managerë¡œ httpx.AsyncClient ìƒëª…ì£¼ê¸° ê´€ë¦¬
- (Phase 5) HttpResponseëŠ” frozen dataclass (Pydantic ë¶ˆí•„ìš” â€” ì§ë ¬í™” ì•ˆ í•¨)
- (Phase 5) ì—ëŸ¬ ì‹œ ì˜ˆì™¸ ëŒ€ì‹  error í•„ë“œ ë°˜í™˜ â€” í˜¸ì¶œìê°€ ì˜ˆì™¸ ì²˜ë¦¬ ì—†ì´ íŒë‹¨ ê°€ëŠ¥
- (Phase 5) 5xx/timeout/connectë§Œ ì¬ì‹œë„, 4xxëŠ” ì¦‰ì‹œ ë°˜í™˜
- (Phase 5) request_delayëŠ” time.monotonic() ê¸°ë°˜ _last_request_time ì¶”ì 
- (Phase 5) 8ê°œ í…ŒìŠ¤íŠ¸, http_client.py 96% ì»¤ë²„ë¦¬ì§€ ë‹¬ì„±
- (Phase 6) Sitemap: dict[str, PageResult] ê¸°ë°˜ O(1) URL ì¡°íšŒ, parent_urlë¡œ íŠ¸ë¦¬ ê´€ê³„ ì¶”ì 
- (Phase 6) Exporter: CrawlResult.model_dump(mode="json") + json.dumps(indent=2) ì¡°í•©
- (Phase 6) ë™ê¸° ì½”ë“œ (async ë¶ˆí•„ìš”) â€” ìˆœìˆ˜ ë°ì´í„° êµ¬ì¡°/ì§ë ¬í™” ì²˜ë¦¬
- (Phase 6) stdlib + pydanticë§Œ ì‚¬ìš© â€” ì™¸ë¶€ ì˜ì¡´ì„± ì—†ìŒ
- (Phase 6) 14ê°œ í…ŒìŠ¤íŠ¸, sitemap.py 100% + exporter.py 100% ì»¤ë²„ë¦¬ì§€ ë‹¬ì„±

### Blockers Encountered
- (ì—†ìŒ)

### Improvements for Future Plans
- Phase 3 (URL Resolver) êµ¬í˜„ ì‹œ CrawlConfig.target_urlì— URL ìœ íš¨ì„± ê²€ì¦ ì¶”ê°€ ê³ ë ¤
- datetime ë¼ìš´ë“œíŠ¸ë¦½ ì •ë°€ë„ í…ŒìŠ¤íŠ¸ ì¶”ê°€ ê³ ë ¤ (í˜„ì¬ Pydanticì´ ISO 8601ë¡œ ì²˜ë¦¬)
- template literal URL íŒ¨í„´ (`${baseUrl}/api/...`) ì§€ì›ì€ Phase 2+ Smart Crawlingì—ì„œ ê³ ë ¤

---

## ğŸ“š References

### Documentation
- PRD ë¬¸ì„œ: `plan/PRD.md`
- Python httpx ê³µì‹ ë¬¸ì„œ: https://www.python-httpx.org/
- Pydantic v2 ê³µì‹ ë¬¸ì„œ: https://docs.pydantic.dev/latest/
- respx ê³µì‹ ë¬¸ì„œ: https://lundberg.github.io/respx/
- ruff ê³µì‹ ë¬¸ì„œ: https://docs.astral.sh/ruff/

### Related Issues
- (ì•„ì§ ì—†ìŒ)

---

## âœ… Final Checklist

**Before marking plan as COMPLETE**:
- [ ] ëª¨ë“  Phase ì™„ë£Œ ë° Quality Gate í†µê³¼
- [ ] ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸
- [ ] ì „ì²´ ì»¤ë²„ë¦¬ì§€ 80%+ ë‹¬ì„±
- [ ] ë³´ì•ˆ ë¦¬ë·° ì™„ë£Œ
- [ ] ëª¨ë“  ì´í•´ê´€ê³„ì ì•Œë¦¼
- [ ] ê³„íš ë¬¸ì„œ ì•„ì¹´ì´ë¸Œ

---

**Plan Status**: ğŸ”„ In Progress
**Next Action**: Phase 2 - HTML Regex Parser
**Blocked By**: None
